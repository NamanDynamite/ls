# -*- coding: utf-8 -*-
"""Scrapping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nu52nhUeB7DWtyXS3P95iyyjStLpvtEE
"""

import requests
import pandas as pd
import time
import re
import json

# ======================================
# CONFIGURATION
# ======================================
from dotenv import load_dotenv
import os

load_dotenv()  
API_KEY = os.getenv("SERPAPI_KEY")
ROLES = ["CTO", "CEO", "Director", "Hiring Manager", "IT Recruiter"]
LOCATIONS = ["USA", "Australia", "Canada", "UK", "Dubai"]
INDUSTRIES = ["IT Services", "Staffing and Recruiting"]

results = []
MAX_RESULTS = 10  # total profiles to fetch

# ======================================
# GEO WORDS / PHRASES TO IGNORE
# ======================================
GEO_WORDS = [
    "Greater", "Area", "Region", "Bay", "City", "Metropolitan", "District",
    "County", "State", "Province", "Territory"
]
GEO_PATTERN = re.compile(
    r"(Greater\s+[A-Z][a-z]+(?:\s[A-Z][a-z]+)?(?:\sArea)?)|"
    r"(San Francisco Bay Area)|(Boston)|(Toronto)|(London)|(New York)|"
    r"(Melbourne)|(Vancouver)|(Sydney)|(Dubai)",
    re.I
)

# ======================================
# UTILITY: CLEAN TEXT
# ======================================
def clean_text(text):
    text = re.sub(r"\s+", " ", text).strip()
    for token in ["| Professional Profile", "Professional Profile", "Profile", "..."]:
        text = text.replace(token, "").strip()
    return text


# ======================================
# EXTRACTION FUNCTION
# ======================================
def extract_company_and_position(title, snippet=""):
    print("\nüîé [DEBUG] Raw title:", title)
    print("üîé [DEBUG] Raw snippet:", snippet)

    name, company, position = "", "", ""
    title = clean_text(title)

    # Skip completely irrelevant results
    if re.search(r"LinkedIn|Professional Profile", title, re.I):
        print("‚ö†Ô∏è [DEBUG] Skipping non-informative LinkedIn profile listing.")
        return "", "", ""

    parts = re.split(r"\s[-|,]\s", title)
    print("üß© [DEBUG] Split parts:", parts)

    # Try parsing "Name - Position at Company"
    if len(parts) >= 2:
        name = parts[0].strip()
        rest = " - ".join(parts[1:]).strip()

        match = re.search(r"(.+?)\s+at\s+(.+)", rest, re.I)
        if match:
            position = match.group(1).strip()
            company = match.group(2).strip()
        else:
            position = rest.strip()

    else:
        # Handle fallback case: only one part, maybe "Name, Position"
        match = re.match(r"(.+?)\s*[-,]\s*(.+)", title)
        if match:
            name, position = match.group(1).strip(), match.group(2).strip()
        else:
            name = title

    # Extract company name from snippet if not found
    if not company and snippet:
        match = re.search(r"\bat\s+([A-Z][A-Za-z0-9&.\- ]+)", snippet)
        if match:
            company = match.group(1).strip()

    # Clean up values
    name, company, position = clean_text(name), clean_text(company), clean_text(position)

    # Handle geographic false positives (like "Greater Boston")
    if GEO_PATTERN.search(position) or re.search(rf"\b({'|'.join(GEO_WORDS)})\b", position):
        print("üßπ [DEBUG] Removed geo-location mistakenly detected as position.")
        position = ""

    if GEO_PATTERN.search(company):
        print("üßπ [DEBUG] Removed geo-location mistakenly detected as company.")
        company = ""

    # Swap if position appears to be a name accidentally
    if re.match(r"^(CTO|CEO|Director|Manager|Recruiter)\b", name, re.I):
        name, position = position, name

    print(f"‚úÖ [DEBUG] Extracted ‚Üí Name: '{name}', Position: '{position}', Company: '{company}'")
    return name, company, position


# ======================================
# SMART LOCATION DETECTION
# ======================================
def detect_location(snippet, fallback_location):
    if not snippet:
        return fallback_location

    for country in LOCATIONS:
        if re.search(rf"\b{country}\b", snippet, re.I):
            return country

    match = GEO_PATTERN.search(snippet)
    if match:
        loc = match.group().strip()
        if any(g in loc for g in GEO_WORDS) and not re.search(r"\b(USA|UK|Canada|Australia|Dubai)\b", loc):
            return fallback_location
        return loc

    return fallback_location


# ======================================
# STEP 1: Search LinkedIn profiles (via SerpAPI)
# ======================================
for role in ROLES:
    for location in LOCATIONS:
        if len(results) >= MAX_RESULTS:
            break

        query = f'{role} {location} IT Services site:linkedin.com/in'
        print(f"\nüîç Searching Google for: {query}")

        params = {"engine": "google", "q": query, "api_key": API_KEY}
        response = requests.get("https://serpapi.com/search", params=params)
        data = response.json()

        print("üìú [DEBUG] SerpAPI JSON keys:", list(data.keys()))

        if "error" in data:
            print("‚ùå SerpAPI error:", data["error"])
            continue

        for item in data.get("organic_results", []):
            if len(results) >= MAX_RESULTS:
                break

            title = item.get("title", "")
            linkedin_url = item.get("link", "")
            snippet = item.get("snippet", "")

            print("\n--------------------------------------------------")
            print(f"üåê [DEBUG] LinkedIn URL: {linkedin_url}")
            print("üìÑ [DEBUG] Title:", title)
            print("üìù [DEBUG] Snippet:", snippet)

            name, company, position = extract_company_and_position(title, snippet)
            if not name or not linkedin_url:
                print("‚ö†Ô∏è [DEBUG] Skipping incomplete record.")
                continue

            detected_location = detect_location(snippet, location)

            print(f"‚û°Ô∏è [DEBUG] FINAL EXTRACTED ‚Üí {name} | {position} | {company} | {detected_location}")

            results.append({
                "Name": name,
                "LinkedIn URL": linkedin_url,
                "Company": company,
                "Position": position,
                "Role": role,
                "Location": detected_location,
                "Snippet": snippet,
            })

        time.sleep(2)

    if len(results) >= MAX_RESULTS:
        break


# ======================================
# STEP 3: Save to CSV
# ======================================
df = pd.DataFrame(results).drop_duplicates(subset=["LinkedIn URL"])

for col in df.columns:
    df[col] = df[col].astype(str).str.strip()

df = df[["Name", "LinkedIn URL", "Company", "Position", "Role", "Location", "Snippet"]]
df.to_csv("linkedin_serpapi_contacts_debug.csv", index=False, encoding="utf-8-sig")

print(f"\n‚úÖ Done! Collected {len(df)} profiles. Results saved to linkedin_serpapi_contacts_debug.csv")

# import requests
# import pandas as pd
# import time
# import re
# import json

# # ======================================
# # CONFIGURATION
# # ======================================
# from dotenv import load_dotenv
# import os

# load_dotenv()  
# API_KEY = os.getenv("SERPAPI_KEY")
# ROLES = ["CTO", "CEO", "Director", "Hiring Manager", "IT Recruiter"]
# LOCATIONS = ["USA", "Australia", "Canada", "UK", "Dubai"]
# INDUSTRIES = ["IT Services", "Staffing and Recruiting"]

# results = []

# # ======================================
# # GEO WORDS / PHRASES TO IGNORE
# # ======================================
# GEO_WORDS = [
#     "Greater", "Area", "Region", "Bay", "City", "Metropolitan", "District",
#     "County", "State", "Province", "Territory"
# ]
# GEO_PATTERN = re.compile(
#     r"(Greater\s+[A-Z][a-z]+(?:\s[A-Z][a-z]+)?(?:\sArea)?)|"
#     r"(San Francisco Bay Area)|(Boston)|(Toronto)|(London)|(New York)|"
#     r"(Melbourne)|(Vancouver)|(Sydney)|(Dubai)",
#     re.I
# )

# # ======================================
# # UTILITY: CLEAN TEXT
# # ======================================
# def clean_text(text):
#     text = re.sub(r"\s+", " ", text).strip()
#     for token in ["| Professional Profile", "Professional Profile", "Profile", "..."]:
#         text = text.replace(token, "").strip()
#     return text


# # ======================================
# # EXTRACTION FUNCTION
# # ======================================
# def extract_company_and_position(title, snippet=""):
#     title = clean_text(title)
#     name, company, position = "", "", ""

#     if re.search(r"LinkedIn|Professional Profile", title, re.I):
#         return "", "", ""

#     parts = re.split(r"\s[-|,]\s", title)
#     if len(parts) >= 2:
#         name = parts[0].strip()
#         rest = " - ".join(parts[1:]).strip()
#         match = re.search(r"(.+?)\s+at\s+(.+)", rest, re.I)
#         if match:
#             position = match.group(1).strip()
#             company = match.group(2).strip()
#         else:
#             position = rest.strip()
#     else:
#         match = re.match(r"(.+?)\s*[-,]\s*(.+)", title)
#         if match:
#             name, position = match.group(1).strip(), match.group(2).strip()
#         else:
#             name = title

#     if not company and snippet:
#         match = re.search(r"\bat\s+([A-Z][A-Za-z0-9&.\- ]+)", snippet)
#         if match:
#             company = match.group(1).strip()

#     name, company, position = clean_text(name), clean_text(company), clean_text(position)

#     if GEO_PATTERN.search(position) or re.search(rf"\b({'|'.join(GEO_WORDS)})\b", position):
#         position = ""
#     if GEO_PATTERN.search(company):
#         company = ""

#     if re.match(r"^(CTO|CEO|Director|Manager|Recruiter)\b", name, re.I):
#         name, position = position, name

#     return name, company, position


# # ======================================
# # SMART LOCATION DETECTION
# # ======================================
# def detect_location(snippet, fallback_location):
#     if not snippet:
#         return fallback_location
#     for country in LOCATIONS:
#         if re.search(rf"\b{country}\b", snippet, re.I):
#             return country
#     match = GEO_PATTERN.search(snippet)
#     if match:
#         loc = match.group().strip()
#         if any(g in loc for g in GEO_WORDS) and not re.search(r"\b(USA|UK|Canada|Australia|Dubai)\b", loc):
#             return fallback_location
#         return loc
#     return fallback_location


# # ======================================
# # STEP 1: Search LinkedIn profiles (via SerpAPI)
# # ======================================
# for role in ROLES:
#     for location in LOCATIONS:
#         query = f'{role} {location} IT Services site:linkedin.com/in'
#         print(f"\nüîç Searching Google for: {query}")

#         params = {"engine": "google", "q": query, "api_key": API_KEY}
#         response = requests.get("https://serpapi.com/search", params=params)
#         data = response.json()

#         if "error" in data:
#             print("‚ùå SerpAPI error:", data["error"])
#             continue

#         for item in data.get("organic_results", []):
#             title = item.get("title", "")
#             linkedin_url = item.get("link", "")
#             snippet = item.get("snippet", "")

#             name, company, position = extract_company_and_position(title, snippet)
#             if not name or not linkedin_url:
#                 continue

#             detected_location = detect_location(snippet, location)
#             results.append({
#                 "Name": name,
#                 "LinkedIn URL": linkedin_url,
#                 "Company": company,
#                 "Position": position,
#                 "Role": role,
#                 "Location": detected_location,
#                 "Snippet": snippet,
#             })

#         time.sleep(2)  # ‚úÖ polite delay to avoid rate limits


# # ======================================
# # STEP 2: Save to CSV
# # ======================================
# df = pd.DataFrame(results).drop_duplicates(subset=["LinkedIn URL"])
# for col in df.columns:
#     df[col] = df[col].astype(str).str.strip()
# df = df[["Name", "LinkedIn URL", "Company", "Position", "Role", "Location", "Snippet"]]
# df.to_csv("linkedin_serpapi_contacts_full.csv", index=False, encoding="utf-8-sig")

# print(f"\n‚úÖ Done! Collected {len(df)} profiles. Results saved to linkedin_contacts_full.csv")

